---
weight: 1
bookFlatSection: false
bookToC: false
title: "10 Perces LoRA Tr√©ning a Legv√©gs≈ë Degener√°ltak Sz√°m√°ra"
summary: "Egy offenz√≠v, etik√°tlan √©s elfogult √∫tmutat√≥ arr√≥l, hogyan potyogtassunk ki kir√°ly LoR√Å-kat minim√°lis er≈ëfesz√≠t√©ssel √©s sz√°m√≠t√°si id≈ëvel."
aliases:
  - /docs/yiff_toolkit/lora_training/10 Perces LoRA Tr√©ning a Legv√©gs≈ë Degener√°ltak Sz√°m√°ra
  - /docs/yiff_toolkit/lora_training/10 Perces LoRA Tr√©ning a Legv√©gs≈ë Degener√°ltak Sz√°m√°ra
  - /docs/yiff_toolkit/lora_training/10_Perces_LoRA_Tr√©ning_a_Legv√©gs≈ë_Degener√°ltak_Sz√°m√°ra
  - /docs/yiff_toolkit/lora_training/10_Perces_LoRA_Tr√©ning_a_Legv√©gs≈ë_Degener√°ltak_Sz√°m√°ra/
  - /docs/yiff_toolkit/lora_training/10-Perces-LoRA-Tr√©ning-a-Legv√©gs≈ë-Degener√°ltak-Sz√°m√°ra
  - /docs/yiff_toolkit/lora_training/10-Perces-LoRA-Tr√©ning-a-Legv√©gs≈ë-Degener√°ltak-Sz√°m√°ra/
  - /hu/docs/yiff_toolkit/lora_training/10 Perces LoRA Tr√©ning a Legv√©gs≈ë Degener√°ltak Sz√°m√°ra
  - /hu/docs/yiff_toolkit/lora_training/10 Perces LoRA Tr√©ning a Legv√©gs≈ë Degener√°ltak Sz√°m√°ra/
  - /hu/docs/yiff_toolkit/lora_training/10_Perces_LoRA_Tr√©ning_a_Legv√©gs≈ë_Degener√°ltak_Sz√°m√°ra
  - /hu/docs/yiff_toolkit/lora_training/10_Perces_LoRA_Tr√©ning_a_Legv√©gs≈ë_Degener√°ltak_Sz√°m√°ra/
  - /hu/docs/yiff_toolkit/lora_training/10-Perces-LoRA-Tr√©ning-a-Legv√©gs≈ë-Degener√°ltak-Sz√°m√°ra
  - /hu/docs/yiff_toolkit/lora_training/10-Perces-LoRA-Tr√©ning-a-Legv√©gs≈ë-Degener√°ltak-Sz√°m√°ra/
  - /hu/docs/yiff_toolkit/lora_training/10 Minute SDXL LoRA Training for the Ultimate Degenerates
  - /hu/docs/yiff_toolkit/lora_training/10 Minute SDXL LoRA Training for the Ultimate Degenerates/
  - /hu/docs/yiff_toolkit/lora_training/10-Minute-SDXL-LoRA-Training-for-the-Ultimate-Degenerates
  - /hu/docs/yiff_toolkit/lora_training/10-Minute-SDXL-LoRA-Training-for-the-Ultimate-Degenerates/
  - /hu/docs/yiff_toolkit/lora_training/10_Minute_SDXL_LoRA_Training_for_the_Ultimate_Degenerates
  - /hu/docs/yiff_toolkit/lora_training/10_Minute_SDXL_LoRA_Training_for_the_Ultimate_Degenerates/
---

<!--markdownlint-disable MD025 MD033 MD034 -->

# 10 Perces LoRA Tr√©ning a Legv√©gs≈ë Degener√°ltak Sz√°m√°ra

---

## Tr√©ning Mont√°zs

---

<div class="video-container">
  <video autoplay loop muted playsinline>
    <source src="https://huggingface.co/k4d3/yiff_toolkit/resolve/main/static/sd-scripts/blaidd_training.mp4" type="video/mp4">
    A b√∂ng√©sz≈ëd nem t√°mogatja a vide√≥ lej√°tsz√°s√°t.
  </video>
</div>

## Bevezet√©s

---

Ez a m√≥dszer egy r√∂vid, k√©zen nem fog√≥ "√∫tmutat√≥", amely egy szuper-k√≠s√©rleti m√≥dszert √≠r le egy SDXL LoRA 80 l√©p√©sben t√∂rt√©n≈ë betan√≠t√°s√°hoz. M≈±k√∂dik mind a Pony Diffusion V6 XL-el, mind a CompassMix XL-el √©s val√≥sz√≠n≈±leg m√©g n√©h√°ny m√°sikkal is. A c√≠mben szerepl≈ë "10 Perces" csak kattint√°svad√°szat, a betan√≠t√°si id≈ë f√ºgg az adathalmazodt√≥l, a l√©p√©sm√©rett≈ël √©s att√≥l, hogy ap√°d mikor vette neked a GPU-dat, de ett≈ël f√ºggetlen√ºl rohadt gyors! A 80 l√©p√©s 40-200 k√©pb≈ël √°ll√≥ karakterekre √©s st√≠lusokra vonatkozik m√©retez√©si probl√©m√°k n√©lk√ºl, csak a kimeneti nevet kell m√≥dos√≠tanod a tr√©ningek k√∂z√∂tt! üò∏

## Be√°ll√≠t√°s √©s Tr√©ning

---

El≈ësz√∂r is sz√ºks√©ged lesz az sd-scripts forkomra, vagy csak az optimaliz√°l√≥-specifikus v√°ltoztat√°sokra a saj√°t forkodban. Ennek m√≥dj√°t {{< i18n-link "/docs/yiff_toolkit/lora_training_guide/Add-Custom-Optimizers" "itt" >}} tal√°lod le√≠rva, de az ottani optimaliz√°l√≥ helyett [ezt](https://raw.githubusercontent.com/ka-de/sd-scripts/lodew/library/optimizers/clybius.py) fogjuk haszn√°lni.

```bash
git clone https://github.com/ka-de/sd-scripts -b dev
```

Az √°ltalam haszn√°lt tr√©ning be√°ll√≠t√°sok a k√∂vetkez≈ëk:

```bash
accelerate launch --num_cpu_threads_per_process=2  "./sdxl_train_network.py" \
    --pretrained_model_name_or_path=/models/ponyDiffusionV6XL_v6StartWithThisOne.safetensors \
    --train_data_dir=/training_dir \
    --resolution="1024,1024" \
    --output_dir="/output_dir" \
    --output_name="yifftoolkit-schnell" \
    --enable_bucket \
    --min_bucket_reso=256 \
    --max_bucket_reso=2048 \
    --network_alpha=4 \
    --save_model_as="safetensors" \
    --network_module="lycoris.kohya" \
    --network_args \
               "preset=full" \
               "conv_dim=256" \
               "conv_alpha=4" \
               "rank_dropout=0" \
               "module_dropout=0" \
               "use_tucker=False" \
               "use_scalar=False" \
               "rank_dropout_scale=False" \
               "algo=locon" \
               "dora_wd=False" \
               "train_norm=False" \
    --network_dropout=0 \
    --lr_scheduler="cosine" \
    --lr_scheduler_args="num_cycles=0.375" \
    --learning_rate=0.0003 \
    --unet_lr=0.0003 \
    --text_encoder_lr=0.0001 \
    --network_dim=8 \
    --no_half_vae \
    --flip_aug \
    --save_every_n_steps=1 \
    --mixed_precision="bf16" \
    --save_precision="fp16" \
    --cache_latents \
    --cache_latents_to_disk \
    --optimizer_type=ClybW \
    --max_grad_norm=1 \
    --max_data_loader_n_workers=8 \
    --bucket_reso_steps=32 \
    --multires_noise_iterations=12 \
    --multires_noise_discount=0.4 \
    --log_prefix=xl-locon \
    --log_with=tensorboard \
    --logging_dir=/output_dir/logs \
    --gradient_accumulation_steps=6 \
    --gradient_checkpointing \
    --train_batch_size=8 \
    --dataset_repeats=1 \
    --shuffle_caption \
    --max_train_steps=80 \
    --sdpa \
    --caption_extension=".txt" \
    --sample_prompts=/training_dir/sample-prompts.txt \
    --sample_sampler="euler_a" \
    --sample_every_n_steps=10
```

Nagyon aj√°nlom, hogy √°ll√≠tsd a `--sample_every_n_steps` √©rt√©k√©t `1`-re legal√°bb egyszer az √©letedben, hogy l√°sd, milyen gyorsan √©s mit tanul a LoRA, l√©legzetel√°ll√≠t√≥ l√°tv√°ny!

## Zsugor√≠t√°s

---

√Åtm√©retez√©s a [resize_lora](https://github.com/elias-gaeros/resize_lora) seg√≠ts√©g√©vel.

```bash
python resize_lora.py -r fro_ckpt=1,thr=-3.55 {model_path} {lora_path}
```

## Darabol√°s

---

A `resize_lora` git t√°rol√≥j√°ban tal√°lsz egy aranyos kis Python szkriptet `chop_blocks.py` n√©ven, ezt haszn√°lhatod arra, hogy kiv√°gd azokat a r√©tegeket a LoRA-db√≥l, amelyek nem tartalmaznak inform√°ci√≥t a betan√≠tott karakterr≈ël/st√≠lusr√≥l/koncepci√≥r√≥l.

Amikor lefuttatod a k√∂vetkez≈ë argumentumokkal a betan√≠tott LoRA-n (nem az √°tm√©retezetten)

```bash
python chop_blocks.py {lora_path} 
```

Egy rejt√©lyes kimenetet kapsz, amely megmutatja, hogy mely blokkok h√°ny r√©teget tartalmaznak:

```r
INFO: Blocks layout:
INFO:   [ 0]  input_blocks.1 layers=9
INFO:   [ 1]  input_blocks.2 layers=9
INFO:   [ 2]  input_blocks.3 layers=3
INFO:   [ 3]  input_blocks.4 layers=78
INFO:   [ 4]  input_blocks.5 layers=75
INFO:   [ 5]  input_blocks.6 layers=3
INFO:   [ 6]  input_blocks.7 layers=318
INFO:   [ 7]  input_blocks.8 layers=315
INFO:   [ 8]  middle_block.0 layers=9
INFO:   [ 9]  middle_block.1 layers=306
INFO:   [10]  middle_block.2 layers=9
INFO:   [11] output_blocks.0 layers=318
INFO:   [12] output_blocks.1 layers=318
INFO:   [13] output_blocks.2 layers=321
INFO:   [14] output_blocks.3 layers=78
INFO:   [15] output_blocks.4 layers=78
INFO:   [16] output_blocks.5 layers=81
INFO:   [17] output_blocks.6 layers=12
INFO:   [18] output_blocks.7 layers=12
INFO:   [19] output_blocks.8 layers=12
INFO: Vector string : "1,INP01,INP02,INP03,INP04,INP05,INP06,INP07,INP08,MID00,MID01,MID02,OUT00,OUT01,OUT02,OUT03,OUT04,OUT05,OUT06,OUT07,OUT08"
INFO: Pass through layers: 264
```

P√©ld√°ul, ha csak az OUT01-et vagy `output_blocks.1`-et szeretn√©d megtartani, a k√∂vetkez≈ët kell haszn√°lnod:

```bash
python chop_blocks.py {‚ö†Ô∏è√°tm√©retezett‚ö†Ô∏è_lora_path} 1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
```

Mivel a vektor sztring els≈ë sz√°ma csak egy ComfyUI node-dal val√≥ kompatibilit√°s miatt van, amir≈ël a k√∂vetkez≈ë bekezd√©sben lesz sz√≥, elfelejtheted, a k√∂vetkez≈ë sz√°m ut√°na az `input_blocks.1`!

Ahhoz, hogy ellen≈ërizd, melyik blokk milyen inform√°ci√≥t tartalmaz, nagyon aj√°nlom, hogy telep√≠tsd a [ComfyUI-Inspire-Pack](https://github.com/ltdrdata/ComfyUI-Inspire-Pack)-et √©s haszn√°ld a `Lora Loader (Block Weight)` node-ot!

<div style="text-align: center;">

{{< blurhash
    src="https://huggingface.co/k4d3/yiff_toolkit/resolve/main/static/sd-scripts/lora_loader.png"
    blurhash="L3O|b2xuWBWB~qof4nWB%MofIUWU"
    width="1045"
    height="805"
    alt="A k√©perny≈ëk√©p a ComfyUI-Inspire-Pack felhaszn√°l√≥i fel√ºlet√©nek egy elem√©t mutatja, konkr√©tan egy 'Lora Loader (Block Weight)' nev≈± node-ot. Ez a node egy vizu√°lis programoz√°si k√∂rnyezet r√©sze, √©s k√ºl√∂nb√∂z≈ë √°ll√≠that√≥ param√©tereket tartalmaz. A node-ban l√°that√≥ f≈ëbb be√°ll√≠t√°sok a 'model', 'clip', 'category_filter', 'lora_name', 'strength_model', 'strength_clip', 'inverse', 'control_after_generate' √©s 'preset'. Minden param√©terhez tartoznak megfelel≈ë beviteli mez≈ëk vagy leg√∂rd√ºl≈ë men√ºk a felhaszn√°l√≥i testreszab√°shoz. A preset mez≈ë egy r√©szletes alfanumerikus karakterl√°ncot tartalmaz, amely egy specifikus konfigur√°ci√≥t reprezent√°l."
>}}

</div>

Gy≈ëz≈ëdj meg r√≥la, hogy a `control_after_generate` √©rt√©ke `fixed` legyen!

Haszn√°lhatod az itt tal√°lhat√≥ el≈ëbe√°ll√≠t√°sokat is az √∂sszes IN, OUT vagy MID blokk ellen≈ërz√©s√©hez, de a l√©nyeges dolgok t√∂bbnyire az OUT1-ben lesznek. <!-- ‚ö†Ô∏è TODO: T√©nyleg t√∂bb LoRA-t kell tr√©ningelnem -->

Miut√°n kital√°ltad, mely blokkokat szeretn√©d megtartani, darabold fel az im√©nt √°tm√©retezett LoRA-t, √©s k√ºldd el a pici LoRA-dat a bar√°taidnak Discordon Nitro el≈ëfizet√©s n√©lk√ºl! üòπ

---

<!--
HUGO_SEARCH_EXCLUDE_START
-->
{{< related-posts related="docs/yiff_toolkit/lora_training/ | docs/yiff_toolkit/comfyui/Experimental-Stuff/ | docs/yiff_toolkit/comfyui/Custom-ComfyUI-Workflow-with-the-Krita-AI-Plugin/" >}}
<!--
HUGO_SEARCH_EXCLUDE_END
-->
