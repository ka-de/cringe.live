---
weight: 2
bookFlatSection: false
bookToC: false
title: "ステップウェイト減衰"
---

<!--markdownlint-disable MD025 -->

# ステップウェイト減衰

ステップウェイト減衰（学習率減衰または重み減衰とも呼ばれる）は、機械学習モデルとニューラルネットワーク最適化アルゴリズムで使用される正則化手法です。以下は、その目的とCompass最適化器での実装方法を簡単に説明したものです：

1. **目的**：
   - モデル内の大きな重みにペナルティを課すことで、過学習を防ぎます。
   - モデルがより単純なパターンを学習するように促し、汎化性能を向上させます。

2. **Compass最適化器での実装**：
   以下がコードでのステップウェイト減衰の適用方法です：

   ```python
   if weight_decay != 0:
       # ステップウェイト減衰を適用
       p.data.mul_(1 - step_size * weight_decay)
   ```

3. **動作原理**：
   - `weight_decay`は減衰の強度を決定するハイパーパラメータです。
   - `step_size`はこの更新ステップに適用される学習率です。
   - 重み（`p.data`）に1よりもわずかに小さい係数を掛けます。
   - この係数は`(1 - step_size * weight_decay)`です。

4. **影響**：
   - 各更新で、すべての重みが少しずつ減少します。
   - 大きな重みは絶対値でより大きく減少します。
   - これにより、損失の削減に大きく貢献しない限り、重みは小さく保たれる傾向があります。

5. **L2正則化との比較**：
   - L2正則化と同様の効果がありますが、ステップウェイト減衰はパラメータ更新ステップで直接適用されます。これにより、特に適応的学習率手法を使用する場合、若干異なる挙動を示すことがあります。

6. **適応的特徴**：
   - `step_size`を使用するため、減衰は現在の有効学習率に適応し、異なるトレーニングフェーズ間でより安定した動作を実現します。

この文脈での「ステップウェイト」という用語は、損失関数内の別個の正則化項ではなく、重み更新プロセスに統合されて各最適化ステップで減衰が適用されることを強調しています。

---

{{< related-posts related="docs/yiff_toolkit/lora_training/ | docs/audio/Audiogen Medium/ | docs/yiff_toolkit/lora_training/dora/" >}}
