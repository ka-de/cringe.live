The recent advancements in deep generative models along with the availability of vast data on the internet have ushered in a new era of text-to-image synthesis \citep{saharia2022photorealistic,ramesh2022hierarchical,balaji2022ediffi}.
These models allow users to transform text prompts into high-quality, visually appealing images, revolutionizing the way we conceive of and interact with digital media~\citep{ko2023large,zhang2023text}.
% These models enable users to synthesize high-quality images through a few concise text prompts, extending their influence beyond the research community to include amateur artists and laypeople interested in creative endeavors. 
Moreover, the models' wide accessibility and user-friendly interfaces extend their influence beyond the research community to laypeople who aspire to create their own artworks.
Among these, Stable Diffusion~\citep{rombach2022high} emerges as one of the pioneering open-source models offering such capabilities.
Its open-source nature has served as a catalyst for a multitude of advances, attracting both researchers and casual users alike. Extensions such as cross-attention control \citep{liu2022compositional} and ControlNet~\citep{zhang2023adding} have further enriched the landscape, broadening the model's appeal and utility.

While these models offer an extensive repertoire of image generation, they often fall short in capturing highly personalized or novel concepts, leading to a burgeoning interest in model customization techniques. Initiatives like DreamBooth~\citep{ruiz2023dreambooth} and Textual Inversion~\citep{gal2023an} have spearheaded efforts in this domain, allowing users to imbue pretrained models like Stable Diffusion with new concepts through a small set of representative images (see \cref{apx:related-works} for detailed related work). Coupled with user-friendly trainers designed to customize Stable Diffusion, the ecosystem now boasts a plethora of specialized models and dedicated platforms that host them---often witnessing the upload of thousands of new models to a single website in just one week.

%\textbf{Contributions\afterhead}
In spite of this burgeoning landscape, our understanding of the intricacies involved in fine-tuning these models remains limited. The complexity of the task---from variations in datasets, image types, and captioning strategies, to the abundance of available methods each with their own sets of hyperparameters---renders it a challenging terrain to navigate. While new methods proposed by researchers offer much potential, they are not always seamlessly integrated into the existing ecosystem, which can hinder comprehensive testing and wider adoption. Moreover, current evaluation paradigms lack a systematic approach that covers the full depth and breadth of what fine-tuning entails. To address these gaps and bridge the divide between research innovations and casual usage, we present our contributions as follows.



% \textbf{Contributions\afterhead}
% In summary, we make the following contributions in our work.
\begin{enumerate}
    \item We develop \lycoris, an open source library dedicated to %\textbf{P}arameter \textbf{E}fficient \textbf{F}ine-\textbf{T}uning (PEFT)
    fine-tuning of Stable Diffusion. This library encapsulates a spectrum of methodologies ranging from the most standard \lora~to a number of emerging strategies such as \loha, \lokr, GLoRA, and $\text{(IA)}^3$ that are newer and lesser-explored in the context of text-to-image models.

    %We develop LyCORIS, an open source library for parameter efficient fine-tuning of Stable Diffusion. It includes several well-established methods, as well as novel approaches that have received less attention in the context of text-to-image models.
    
    \item To enable rigorous comparisons between methods, we propose a comprehensive evaluation framework that incorporates a wide range of metrics, capturing key aspects such as concept fidelity, text-image alignment, image diversity, and preservation of the base model's style.
    \item 
    %{\color{blue}We fine-tune hundreds of diffusion models and generate millions of images to compare the performances of different algorithms implemented in \lycoris~and to assess the impacts of various hyperparameters, offering insights into how these factors influence the results. Concurrently, we underscore the complexities inherent in model evaluation, advocating for the development and adoption of more comprehensive and systematic evaluation processes.} 
    Through extensive experiments, we compare the performances of different fine-tuning algorithms implemented in \lycoris~and assess the impacts of various hyperparameters, offering insights into how these factors influence the results.
    Concurrently, we underscore the complexities inherent in model evaluation, advocating for the development and adoption of more comprehensive and systematic evaluation processes.
\end{enumerate}

% The remainder of this paper is organized as follows. In \cref{sec:pre}, we describe the preliminaries of Stable Diffusion and \lora. Subsequently, \cref{sec:lyco_lib} introduces the design objective and the implemented algorithms, including \lora, \loha, and \lokr. Then, we present our evaluation framework in \cref{sec:evaluation}. \cref{sec:exp} is dedicated to the experimental results and discusses several observations. Finally, we conclude this paper in \cref{sec:con}.
