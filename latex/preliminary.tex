In this section, we briefly review the two core components of our study: Stable Diffusion and \lora~for model customization.

\subsection{Stable Diffusion}
\label{subsec:sd}

Diffusion models~\citep{sohl2015deep,ho2020denoising} are a family of probabilistic generative models that are trained to capture a data distribution %$\distribution(\mathbf{\variable}_{0})$
through a sequence of denoising operations.
Given an initial noise map $\mathbf{\variable}_{\nDiffsteps} \sim \gaussian(0, \Id)$, the models iteratively refine it by reversing the diffusion process until it is synthesized into a desired image $\variable_{0}$. These models can be conditioned on elements such as text prompts, class labels, or low-resolution images,
allowing conditioned generation. 

Specifically, our work is based on Stable Diffusion, a text-to-image latent diffusion model~\citep{rombach2022high} pretrained on the LAION 5-billion image dataset~\citep{schuhmann2022laion}.
Latent diffusion models reduce the cost of diffusion models by shifting the denoising operation into the latent space of a pre-trained variational autoencoder, composed of an encoder $\vaeencoder$ and a decoder $\vaedecoder$.
During training, the noise is added to the encoder's latent output $\latent=\vaeencoder(\variable_0)$ for each time step $\run\in \{0, \dots, \nDiffsteps\}$, resulting in a noisy latent $\latent_{\run}$.
Then, the model is trained to predict the noise applied to $\latent_{\run}$, given text conditioning $\textcond=\textencoder (\textdes)$ obtained from an image description $\textdes$ (also known as the image's caption) using a text encoder~$\textencoder$.
Formally, with $\param$ denoting the parameter of the denoising U-Net and $\diffnoise_\param(\cdot)$ representing the predicted noise from this model, we aim to minimize
%
\begin{equation}
\label{eq:SD-loss}
\loss(\param) = \mathbb{E}_{\variable_0,\textcond,\diffnoise,\run}[||\diffnoise - \diffnoise_\theta(\latent_{\run},\run,\textcond)||^2_2],
\end{equation}
%
where $\variable_0$, $\textcond$ are drawn from the dataset, $\diffnoise\sim\gaussian(0, \Id)$, and $\run$ is uniformly drawn from $\oneto{\nDiffsteps}$. 
 
% In this study, we employ , a text-to-image generator model based on Latent Diffusion Models (LDM) \cite{rombach2022highresolution}. LDM is a class of generative diffusion models $\mathcal{D}_\theta (\diffnoise, c)$ designed to denoise a specified noise map $\diffnoise \in \R^{h \times w}$ while adhering to an input  Stable Diffusion is then trained with a denoising U-Net $\diffnoise_\theta$ attached with transformer blocks that take in the text conditioning $c$ and a latent feature $z$ at a $t$-th denoising step. 



\subsection{Model Customization With \lora}

To enable more personalized experiences, model customization has been proposed as a means to adapt foundational models to specific domains or concepts.
In the case of Stable Diffusion, this frequently involves fine-tuning a pretrained model by minimizing the original loss function \eqref{eq:SD-loss} on a new dataset, containing as few as a single image for each target concept. 
In this process, we introduce a \emph{concept descriptor} 
$\trainingword$ for each target concept, comprising a neutral \emph{trigger word} 
$\triggerword$ and an optional \emph{class word} 
$\classword$ to denote the category to which the concept belongs. 
This concept descriptor is intended for use in both the image captions and text prompts.
While it is possible to include a prior-preservation loss by utilizing a set of regularization images~\citep{ruiz2023dreambooth,kumari2023multi}, we have chosen not to employ this strategy in the current study.
%(see \cref{apx:dataset} for a detailed discussion).

%\textbf{Model Customization} has emerged in this rapidly evolving domain of deep learning because of the creation of foundational models, and it is a way to enhance performance and adaptability for a domain-specific task with a small amount of data. In image generation such as Stable Diffusion, prior-preservation loss \cite{ruiz2023dreambooth} has become a prominent technique in fine-tuning models to a specific task without the loss of pre-training knowledge. This loss mechanism prevents overfitting or even the loss of knowledge that was learned in the initial training on a larger dataset. It is a regularizer that leverages the generalizable features learned during the model pre-training stage and adapts to new knowledge efficiently. Prior-preservation loss can sometimes improve generalization by constraining the model to remain similar to its original pre-trained parameters. However, we have chosen not to incorporate this technique in our current approach. More discussions on not incorporating prior-preservation loss can be found here (\cref{apx:dataset}). 


\disclose{\paragraph{Low-Rank Adaptation (LoRA)\afterhead}}{\textbf{Low-Rank Adaptation (LoRA)\afterhead}}
%
When integrated into the model customization process, Low-Rank Adaptation (\lora) could substantially reduce the number of parameters that need to be updated. It was originally developed for large language models~\citep{hu2021lora}, and later adapted for Stable Diffusion by \cite{githublora}. 
% By further incorporating \lora~in the fine-tuning process, we substantially reduce the number of parameters that need to be updated. 
% Originally developed for large language models~\citep{hu2021lora}, this method was adapted for Stable Diffusion by \cite{githublora}. 
\lora~operates by constraining fine-tuning to a low-rank subspace of the original parameter space.
More specifically, the \emph{weight update} $\Delta\weightmat \in \R^{\vdim\times \vdimalt}$ is pre-factorized into two low-rank matrixes $\leftmat \in \R^{\vdim\times \dimension}, \rightmat \in \R^{\dimension \times \vdimalt}$, where $\vdim, \vdimalt$ are the dimensions of the original model parameter, $\dimension$ is the dimension of the low-rank matrix, and $\dimension \ll \min(\vdim,\vdimalt)$. 
%The low-rank matrices are further injected into the foundational model to capture the model update. 
During fine-tuning, the foundational model parameter $\weightmat_{0}$ remains frozen, and only the low-rank matrices are updated.
Formally, the forward pass of $\hidden^{\prime} = \weightmat_{0}\hidden+\bias$ is modified to:
%the updated weight matrix is expressed as:
% \[
% \weightmat' = \weightmat_0 + \scale 
% \Delta \weightmat \quad \text{where} \quad \Delta \weightmat = \leftmat\rightmat, \quad \scale = \alpha / \dimension
% \]
\begin{equation}\label{eq:lora}
\hidden^{\prime} = \weightmat_{0}\hidden +\bias + \scale \Delta \weightmat \hidden  =  \weightmat_{0}\hidden  +\bias+ \scale \leftmat\rightmat \hidden,
\end{equation}
where $\scale$ is a \emph{merge ratio} that balances the retention of pretrained model information and its adaptation to the target concepts.\footnote{Setting $\scale$ is mathematically equivalent to scaling the initialization of $\leftmat$ and $\rightmat$ by $\sqrt{\scale}$ and scaling the learning rate by $\sqrt{\scale}$ or $\scale$, depending on the used optimizer. See \cref{apx:merge-ratio} for a generalization of this result.}
Following \cite{hu2021lora}, we further define $\alpha=\scale\dimension$ so that $\scale=\alpha/\dimension$.

%\(\alpha\) serves as a balancing factor that mediates between retaining knowledge from the pre-trained model and adapting it to new tasks, effectively acting as a merging ratio. 



%the forward pass of $\hidden^{\prime} = \weightmat_{0}\hidden$ is modified to:
% \begin{equation}\label{equ:lora}
% \hidden^{\prime} = \weightmat_{0}\hidden + \scale \Delta \weightmat \hidden  =  \weightmat_{0}\hidden + \scale \leftmat\rightmat \hidden 
% \end{equation}
% where $\scale = \frac{\alpha}{r}$, $\alpha$ is a scalar in $r$ that balances the retention of pre-trained model information and its adaptation to a downstream task.

%The de facto workflow of many natural language processing applications relies on fine-tuning one pre-trained large language model to accommodate multiple downstream tasks. The Low-Rank Adapter (LoRA) presents a compelling methodology for adapting LLMs, offering advantages in terms of reduced storage requirements, minimal memory overhead, and no extra inference latency. 

%The intuition behind the \lora~derives from the observation made on the training LLMs, where the learned over-parametrized models reside on a low intrinsic dimension. \lora~further hypothesizes that change in mode parameter during fine-tuning similarly exhibit a low "intrinsic rank". Therefore, 
% \cite{githublora} and garnered outstanding results. The essential idea is that LoRA is used to constrain the fine-tuning within a low-rank space of the broader parameter space, which avoids the risk of overfitting the model when data is extremely limited. 

% \begin{equation}
% W' = W + \scale \Delta W \label{LoRA weight}
% \end{equation}

% where $\Delta W = BA$, and $\scale = \alpha / \dimension$. $\alpha$ is a scalar that balances the retention of pre-trained model information and its adaptation to a new task, which can be described as the merging ratio.
